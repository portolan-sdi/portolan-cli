# Tier 3 CI - Scheduled nightly checks
# See context/shared/documentation/ci.md for the full CI strategy
#
# Philosophy: These are the "expensive" checks that would slow down PRs.
# They still fail the build - we track trends but don't accept regressions.
name: Nightly
on:
  schedule:
    - cron: '0 4 * * *'  # 4 AM UTC daily
  workflow_dispatch:  # Allow manual triggering

jobs:
  mutation:
    name: Mutation Testing
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v6

      - name: Install uv
        uses: astral-sh/setup-uv@v7

      - name: Set up Python
        run: uv python install 3.11

      - name: Install dependencies
        run: uv sync --all-extras

      - name: Run mutation testing
        run: |
          # mutmut 3.x auto-detects paths and tests directory
          uv run mutmut run

      - name: Check mutation score
        run: |
          # Get all results (mutmut 3.x outputs text, not JSON/XML)
          uv run mutmut results --all true > mutation-results.txt

          # Count mutants by status from text output
          # Format: "function_name: status" where status is killed/survived/no tests
          KILLED=$(grep -c ': killed$' mutation-results.txt || echo 0)
          SURVIVED=$(grep -c ': survived$' mutation-results.txt || echo 0)
          NO_TESTS=$(grep -c ': no tests$' mutation-results.txt || echo 0)

          # Total testable mutants (exclude "no tests" from calculation)
          TESTABLE=$((KILLED + SURVIVED))

          echo "Mutation results:"
          echo "  Killed: $KILLED"
          echo "  Survived: $SURVIVED"
          echo "  No tests: $NO_TESTS"
          echo "  Total testable: $TESTABLE"

          if [ "$TESTABLE" -eq 0 ]; then
            echo "No testable mutations generated - check if source code has test coverage"
            exit 0
          fi

          # Calculate kill rate (higher is better)
          KILL_RATE=$(echo "scale=2; $KILLED * 100 / $TESTABLE" | bc)
          echo "Mutation kill rate: $KILL_RATE% ($KILLED killed, $SURVIVED survived)"

          # Fail if kill rate drops below 60%
          # This threshold should increase as the codebase matures
          MIN_KILL_RATE=60
          if [ $(echo "$KILL_RATE < $MIN_KILL_RATE" | bc) -eq 1 ]; then
            echo "::error::Mutation kill rate ($KILL_RATE%) is below threshold ($MIN_KILL_RATE%)"
            echo "Tests are not catching enough bugs. Review survived mutants."
            exit 1
          fi

      - name: Generate mutation report
        if: always()
        run: uv run mutmut html || true

      - name: Upload mutation report
        uses: actions/upload-artifact@v6
        with:
          name: mutation-report
          path: |
            html/
            mutation-results.txt
          retention-days: 30
        if: always()

  benchmark:
    name: Performance Benchmarks
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v6
        with:
          fetch-depth: 0  # Full history to compare with previous runs

      - name: Install uv
        uses: astral-sh/setup-uv@v7

      - name: Set up Python
        run: uv python install 3.11

      - name: Install dependencies
        run: uv sync --all-extras

      - name: Run benchmarks
        run: |
          # Run benchmarks and save results
          uv run pytest tests/ \
            -m benchmark \
            --benchmark-json=benchmark-results.json \
            --benchmark-autosave \
            -v

      - name: Check for performance regression
        run: |
          # If baseline exists, compare and fail on >20% regression
          if [ -f .benchmarks/baseline.json ]; then
            uv run pytest-benchmark compare \
              benchmark-results.json \
              .benchmarks/baseline.json \
              --fail-on=20
          else
            echo "No baseline found. This run will establish the baseline."
            mkdir -p .benchmarks
            cp benchmark-results.json .benchmarks/baseline.json
          fi

      - name: Upload benchmark results
        uses: actions/upload-artifact@v6
        with:
          name: benchmark-results
          path: benchmark-results.json
          retention-days: 90
        if: always()

  network-live:
    name: Live Network Tests
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v6

      - name: Install uv
        uses: astral-sh/setup-uv@v7

      - name: Set up Python
        run: uv python install 3.11

      - name: Install dependencies
        run: uv sync --all-extras

      - name: Run network tests against live services
        run: |
          uv run pytest tests/ \
            -m network \
            --timeout=120 \
            -v

  dependency-check:
    name: Dependency Audit
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v6

      - name: Install uv
        uses: astral-sh/setup-uv@v7

      - name: Set up Python
        run: uv python install 3.11

      - name: Install dependencies
        run: uv sync --all-extras

      - name: Full security audit
        run: |
          echo "=== Dependency security audit ==="
          uv run pip-audit --strict

      - name: Check for outdated dependencies
        run: |
          echo "=== Outdated dependencies ==="
          uv pip list --outdated
          # Note: This is informational, not a failure condition
