# v0.4 Metadata + Validation Implementation Plan

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** Implement metadata extraction, validation rules, and the `portolan check` command for local catalog validation.

**Architecture:** Following ADR-0011 (MVP Validation Framework), we build an extensible validation system with rule classes. Metadata extraction provides extent, schema, and CRS from GeoParquet/COG files. The `portolan check` CLI wraps the validation API.

**Tech Stack:** Python 3.10+, Click (CLI), pystac (STAC), pyarrow (GeoParquet metadata), rasterio (COG metadata)

**ADRs to follow:**
- ADR-0007: CLI wraps Python API (all logic in library layer)
- ADR-0009: Output modes (--verbose, --json, --fix)
- ADR-0010: Delegate to upstream (content validation delegated, we do structural)
- ADR-0011: MVP validation framework (start simple, design for extensibility)

---

## Task 1: Validation Results Data Structures

Create the data structures for validation results. These are used by all validation rules.

**Files:**
- Create: `portolan_cli/validation/__init__.py`
- Create: `portolan_cli/validation/results.py`
- Test: `tests/unit/test_validation_results.py`

**Step 1: Write the failing tests for ValidationResult**

```python
# tests/unit/test_validation_results.py
"""Tests for validation result data structures."""

from __future__ import annotations

import pytest

from portolan_cli.validation.results import (
    Severity,
    ValidationResult,
    ValidationReport,
)


class TestSeverity:
    """Tests for Severity enum."""

    @pytest.mark.unit
    def test_severity_has_error_level(self) -> None:
        """Severity must have ERROR level for blocking issues."""
        assert Severity.ERROR.value == "error"

    @pytest.mark.unit
    def test_severity_has_warning_level(self) -> None:
        """Severity must have WARNING level for non-blocking issues."""
        assert Severity.WARNING.value == "warning"

    @pytest.mark.unit
    def test_severity_has_info_level(self) -> None:
        """Severity must have INFO level for suggestions."""
        assert Severity.INFO.value == "info"


class TestValidationResult:
    """Tests for ValidationResult dataclass."""

    @pytest.mark.unit
    def test_result_stores_rule_name(self) -> None:
        """ValidationResult must store which rule produced it."""
        result = ValidationResult(
            rule_name="test_rule",
            passed=True,
            severity=Severity.ERROR,
            message="All good",
        )
        assert result.rule_name == "test_rule"

    @pytest.mark.unit
    def test_result_stores_pass_status(self) -> None:
        """ValidationResult must indicate pass/fail."""
        result = ValidationResult(
            rule_name="test_rule",
            passed=False,
            severity=Severity.ERROR,
            message="Failed",
        )
        assert result.passed is False

    @pytest.mark.unit
    def test_result_stores_severity(self) -> None:
        """ValidationResult must store severity level."""
        result = ValidationResult(
            rule_name="test_rule",
            passed=False,
            severity=Severity.WARNING,
            message="Warning",
        )
        assert result.severity == Severity.WARNING

    @pytest.mark.unit
    def test_result_stores_message(self) -> None:
        """ValidationResult must store human-readable message."""
        result = ValidationResult(
            rule_name="test_rule",
            passed=True,
            severity=Severity.INFO,
            message="Looks good",
        )
        assert result.message == "Looks good"

    @pytest.mark.unit
    def test_result_stores_optional_fix_hint(self) -> None:
        """ValidationResult can store optional fix hint."""
        result = ValidationResult(
            rule_name="test_rule",
            passed=False,
            severity=Severity.ERROR,
            message="Missing field",
            fix_hint="Run 'portolan check --fix' to add defaults",
        )
        assert result.fix_hint == "Run 'portolan check --fix' to add defaults"

    @pytest.mark.unit
    def test_result_fix_hint_defaults_to_none(self) -> None:
        """ValidationResult.fix_hint defaults to None."""
        result = ValidationResult(
            rule_name="test_rule",
            passed=True,
            severity=Severity.INFO,
            message="OK",
        )
        assert result.fix_hint is None


class TestValidationReport:
    """Tests for ValidationReport aggregate."""

    @pytest.mark.unit
    def test_report_stores_results(self) -> None:
        """ValidationReport must store list of results."""
        results = [
            ValidationResult("rule1", True, Severity.INFO, "OK"),
            ValidationResult("rule2", False, Severity.ERROR, "Failed"),
        ]
        report = ValidationReport(results=results)
        assert len(report.results) == 2

    @pytest.mark.unit
    def test_report_passed_true_when_all_pass(self) -> None:
        """ValidationReport.passed is True when all results pass."""
        results = [
            ValidationResult("rule1", True, Severity.INFO, "OK"),
            ValidationResult("rule2", True, Severity.WARNING, "OK"),
        ]
        report = ValidationReport(results=results)
        assert report.passed is True

    @pytest.mark.unit
    def test_report_passed_false_when_any_error_fails(self) -> None:
        """ValidationReport.passed is False when any ERROR severity fails."""
        results = [
            ValidationResult("rule1", True, Severity.INFO, "OK"),
            ValidationResult("rule2", False, Severity.ERROR, "Failed"),
        ]
        report = ValidationReport(results=results)
        assert report.passed is False

    @pytest.mark.unit
    def test_report_passed_true_when_only_warnings_fail(self) -> None:
        """ValidationReport.passed is True when only WARNINGs fail (non-blocking)."""
        results = [
            ValidationResult("rule1", True, Severity.INFO, "OK"),
            ValidationResult("rule2", False, Severity.WARNING, "Warn"),
        ]
        report = ValidationReport(results=results)
        assert report.passed is True

    @pytest.mark.unit
    def test_report_errors_property(self) -> None:
        """ValidationReport.errors returns only failed ERROR results."""
        results = [
            ValidationResult("rule1", True, Severity.ERROR, "OK"),
            ValidationResult("rule2", False, Severity.ERROR, "Failed"),
            ValidationResult("rule3", False, Severity.WARNING, "Warn"),
        ]
        report = ValidationReport(results=results)
        errors = report.errors
        assert len(errors) == 1
        assert errors[0].rule_name == "rule2"

    @pytest.mark.unit
    def test_report_warnings_property(self) -> None:
        """ValidationReport.warnings returns only failed WARNING results."""
        results = [
            ValidationResult("rule1", False, Severity.ERROR, "Error"),
            ValidationResult("rule2", False, Severity.WARNING, "Warn1"),
            ValidationResult("rule3", False, Severity.WARNING, "Warn2"),
        ]
        report = ValidationReport(results=results)
        warnings = report.warnings
        assert len(warnings) == 2

    @pytest.mark.unit
    def test_report_to_dict_for_json_output(self) -> None:
        """ValidationReport.to_dict() returns JSON-serializable dict."""
        results = [
            ValidationResult("rule1", True, Severity.INFO, "OK"),
        ]
        report = ValidationReport(results=results)
        d = report.to_dict()
        assert d["passed"] is True
        assert len(d["results"]) == 1
        assert d["results"][0]["rule_name"] == "rule1"

    @pytest.mark.unit
    def test_empty_report_passes(self) -> None:
        """Empty ValidationReport passes (no rules = no failures)."""
        report = ValidationReport(results=[])
        assert report.passed is True
```

**Step 2: Run tests to verify they fail**

Run: `uv run pytest tests/unit/test_validation_results.py -v`
Expected: FAIL with "ModuleNotFoundError: No module named 'portolan_cli.validation'"

**Step 3: Create the validation package and results module**

```python
# portolan_cli/validation/__init__.py
"""Validation framework for Portolan catalogs.

This module provides the public API for validating catalogs:
- check(): Run validation rules against a catalog
- ValidationReport: Aggregate validation results

Per ADR-0011, this is an MVP that validates catalog structure only.
Dataset-specific and remote validation comes in later versions.
"""

from portolan_cli.validation.results import (
    Severity,
    ValidationReport,
    ValidationResult,
)

__all__ = [
    "Severity",
    "ValidationReport",
    "ValidationResult",
]
```

```python
# portolan_cli/validation/results.py
"""Validation result data structures.

These classes capture the output of validation rules and aggregate
them into reports for CLI display and JSON export.
"""

from __future__ import annotations

from dataclasses import dataclass, field
from enum import Enum
from typing import Any


class Severity(Enum):
    """Severity level for validation results.

    ERROR: Blocks catalog operations (validation fails)
    WARNING: Non-blocking issue (validation passes with warnings)
    INFO: Suggestion for improvement (always passes)
    """

    ERROR = "error"
    WARNING = "warning"
    INFO = "info"


@dataclass(frozen=True)
class ValidationResult:
    """Result from a single validation rule.

    Attributes:
        rule_name: Identifier for the rule that produced this result.
        passed: Whether the validation passed.
        severity: How serious a failure is (ERROR blocks, WARNING doesn't).
        message: Human-readable description of the result.
        fix_hint: Optional suggestion for fixing the issue.
    """

    rule_name: str
    passed: bool
    severity: Severity
    message: str
    fix_hint: str | None = None

    def to_dict(self) -> dict[str, Any]:
        """Convert to JSON-serializable dict."""
        d: dict[str, Any] = {
            "rule_name": self.rule_name,
            "passed": self.passed,
            "severity": self.severity.value,
            "message": self.message,
        }
        if self.fix_hint:
            d["fix_hint"] = self.fix_hint
        return d


@dataclass
class ValidationReport:
    """Aggregate of all validation results.

    Attributes:
        results: List of individual validation results.
    """

    results: list[ValidationResult] = field(default_factory=list)

    @property
    def passed(self) -> bool:
        """True if no ERROR-severity rules failed."""
        return not any(
            not r.passed and r.severity == Severity.ERROR for r in self.results
        )

    @property
    def errors(self) -> list[ValidationResult]:
        """Return only failed ERROR-severity results."""
        return [
            r for r in self.results if not r.passed and r.severity == Severity.ERROR
        ]

    @property
    def warnings(self) -> list[ValidationResult]:
        """Return only failed WARNING-severity results."""
        return [
            r for r in self.results if not r.passed and r.severity == Severity.WARNING
        ]

    def to_dict(self) -> dict[str, Any]:
        """Convert to JSON-serializable dict for --json output."""
        return {
            "passed": self.passed,
            "error_count": len(self.errors),
            "warning_count": len(self.warnings),
            "results": [r.to_dict() for r in self.results],
        }
```

**Step 4: Run tests to verify they pass**

Run: `uv run pytest tests/unit/test_validation_results.py -v`
Expected: All 17 tests PASS

**Step 5: Commit**

```bash
git add portolan_cli/validation/__init__.py portolan_cli/validation/results.py tests/unit/test_validation_results.py
git commit -m "$(cat <<'EOF'
feat(validation): add ValidationResult and ValidationReport data structures

Introduces the core data structures for the validation framework:
- Severity enum (ERROR, WARNING, INFO)
- ValidationResult for individual rule outcomes
- ValidationReport for aggregating results with pass/fail logic

Per ADR-0011: ERROR failures block, WARNING failures don't.

Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>
EOF
)"
```

---

## Task 2: ValidationRule Base Class

Create the base class that all validation rules inherit from.

**Files:**
- Create: `portolan_cli/validation/rules.py`
- Modify: `portolan_cli/validation/__init__.py`
- Test: `tests/unit/test_validation_rules.py`

**Step 1: Write failing tests for ValidationRule**

```python
# tests/unit/test_validation_rules.py
"""Tests for validation rule base class and registry."""

from __future__ import annotations

from pathlib import Path

import pytest

from portolan_cli.validation.results import Severity, ValidationResult
from portolan_cli.validation.rules import ValidationRule


class TestValidationRule:
    """Tests for ValidationRule base class."""

    @pytest.mark.unit
    def test_rule_has_name_attribute(self) -> None:
        """ValidationRule must have a name for identification."""

        class TestRule(ValidationRule):
            name = "test_rule"
            severity = Severity.ERROR
            description = "A test rule"

            def check(self, catalog_path: Path) -> ValidationResult:
                return self._pass("OK")

        rule = TestRule()
        assert rule.name == "test_rule"

    @pytest.mark.unit
    def test_rule_has_severity_attribute(self) -> None:
        """ValidationRule must have a severity level."""

        class TestRule(ValidationRule):
            name = "test_rule"
            severity = Severity.WARNING
            description = "A test rule"

            def check(self, catalog_path: Path) -> ValidationResult:
                return self._pass("OK")

        rule = TestRule()
        assert rule.severity == Severity.WARNING

    @pytest.mark.unit
    def test_rule_has_description(self) -> None:
        """ValidationRule must have a description for --verbose output."""

        class TestRule(ValidationRule):
            name = "test_rule"
            severity = Severity.INFO
            description = "Checks something important"

            def check(self, catalog_path: Path) -> ValidationResult:
                return self._pass("OK")

        rule = TestRule()
        assert rule.description == "Checks something important"

    @pytest.mark.unit
    def test_rule_check_returns_validation_result(self, tmp_path: Path) -> None:
        """check() must return a ValidationResult."""

        class TestRule(ValidationRule):
            name = "test_rule"
            severity = Severity.ERROR
            description = "Test"

            def check(self, catalog_path: Path) -> ValidationResult:
                return self._pass("Passed")

        rule = TestRule()
        result = rule.check(tmp_path)
        assert isinstance(result, ValidationResult)
        assert result.passed is True

    @pytest.mark.unit
    def test_rule_pass_helper_creates_passing_result(self, tmp_path: Path) -> None:
        """_pass() helper creates a passing ValidationResult."""

        class TestRule(ValidationRule):
            name = "my_rule"
            severity = Severity.ERROR
            description = "Test"

            def check(self, catalog_path: Path) -> ValidationResult:
                return self._pass("Everything OK")

        rule = TestRule()
        result = rule.check(tmp_path)
        assert result.passed is True
        assert result.rule_name == "my_rule"
        assert result.severity == Severity.ERROR
        assert result.message == "Everything OK"

    @pytest.mark.unit
    def test_rule_fail_helper_creates_failing_result(self, tmp_path: Path) -> None:
        """_fail() helper creates a failing ValidationResult."""

        class TestRule(ValidationRule):
            name = "my_rule"
            severity = Severity.ERROR
            description = "Test"

            def check(self, catalog_path: Path) -> ValidationResult:
                return self._fail("Something wrong")

        rule = TestRule()
        result = rule.check(tmp_path)
        assert result.passed is False
        assert result.rule_name == "my_rule"
        assert result.message == "Something wrong"

    @pytest.mark.unit
    def test_rule_fail_helper_accepts_fix_hint(self, tmp_path: Path) -> None:
        """_fail() helper can include a fix hint."""

        class TestRule(ValidationRule):
            name = "my_rule"
            severity = Severity.ERROR
            description = "Test"

            def check(self, catalog_path: Path) -> ValidationResult:
                return self._fail("Missing X", fix_hint="Add X to catalog.json")

        rule = TestRule()
        result = rule.check(tmp_path)
        assert result.fix_hint == "Add X to catalog.json"

    @pytest.mark.unit
    def test_rule_is_abstract(self) -> None:
        """ValidationRule.check() must be implemented by subclasses."""
        with pytest.raises(TypeError, match="abstract"):
            ValidationRule()  # type: ignore[abstract]
```

**Step 2: Run tests to verify they fail**

Run: `uv run pytest tests/unit/test_validation_rules.py -v`
Expected: FAIL with "ImportError: cannot import name 'ValidationRule'"

**Step 3: Implement ValidationRule base class**

```python
# portolan_cli/validation/rules.py
"""Validation rule base class and built-in rules.

Each rule checks one aspect of catalog validity. Rules are designed
to be unit-testable in isolation and composable into a validation pipeline.

Per ADR-0011, v0.4 rules only check catalog structure, not dataset contents.
"""

from __future__ import annotations

from abc import ABC, abstractmethod
from pathlib import Path

from portolan_cli.validation.results import Severity, ValidationResult


class ValidationRule(ABC):
    """Base class for all validation rules.

    Subclasses must define:
        name: Unique identifier for the rule
        severity: ERROR (blocking) or WARNING (non-blocking)
        description: Human-readable explanation for --verbose

    Subclasses must implement:
        check(): Run the validation and return a result
    """

    name: str
    severity: Severity
    description: str

    @abstractmethod
    def check(self, catalog_path: Path) -> ValidationResult:
        """Run this validation rule against a catalog.

        Args:
            catalog_path: Path to the .portolan directory.

        Returns:
            ValidationResult indicating pass/fail with message.
        """
        ...

    def _pass(self, message: str) -> ValidationResult:
        """Helper to create a passing result."""
        return ValidationResult(
            rule_name=self.name,
            passed=True,
            severity=self.severity,
            message=message,
        )

    def _fail(self, message: str, *, fix_hint: str | None = None) -> ValidationResult:
        """Helper to create a failing result."""
        return ValidationResult(
            rule_name=self.name,
            passed=False,
            severity=self.severity,
            message=message,
            fix_hint=fix_hint,
        )
```

**Step 4: Update validation/__init__.py exports**

```python
# portolan_cli/validation/__init__.py
"""Validation framework for Portolan catalogs.

This module provides the public API for validating catalogs:
- check(): Run validation rules against a catalog
- ValidationReport: Aggregate validation results
- ValidationRule: Base class for custom rules

Per ADR-0011, this is an MVP that validates catalog structure only.
Dataset-specific and remote validation comes in later versions.
"""

from portolan_cli.validation.results import (
    Severity,
    ValidationReport,
    ValidationResult,
)
from portolan_cli.validation.rules import ValidationRule

__all__ = [
    "Severity",
    "ValidationReport",
    "ValidationResult",
    "ValidationRule",
]
```

**Step 5: Run tests to verify they pass**

Run: `uv run pytest tests/unit/test_validation_rules.py -v`
Expected: All 8 tests PASS

**Step 6: Commit**

```bash
git add portolan_cli/validation/rules.py portolan_cli/validation/__init__.py tests/unit/test_validation_rules.py
git commit -m "$(cat <<'EOF'
feat(validation): add ValidationRule abstract base class

Provides the base class for all validation rules with:
- Required name, severity, description attributes
- Abstract check() method for subclass implementation
- _pass() and _fail() helpers for creating results

Follows ADR-0011 extensible design for incremental rule addition.

Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>
EOF
)"
```

---

## Task 3: CatalogExistsRule - First Concrete Rule

Implement the first validation rule: check that .portolan directory exists.

**Files:**
- Modify: `portolan_cli/validation/rules.py`
- Test: `tests/unit/test_validation_rules.py` (extend)

**Step 1: Write failing tests for CatalogExistsRule**

Add to `tests/unit/test_validation_rules.py`:

```python
from portolan_cli.validation.rules import ValidationRule, CatalogExistsRule


class TestCatalogExistsRule:
    """Tests for CatalogExistsRule."""

    @pytest.mark.unit
    def test_passes_when_portolan_dir_exists(self, tmp_path: Path) -> None:
        """Rule passes when .portolan directory exists."""
        portolan_dir = tmp_path / ".portolan"
        portolan_dir.mkdir()

        rule = CatalogExistsRule()
        result = rule.check(tmp_path)

        assert result.passed is True
        assert "exists" in result.message.lower()

    @pytest.mark.unit
    def test_fails_when_portolan_dir_missing(self, tmp_path: Path) -> None:
        """Rule fails when .portolan directory is missing."""
        rule = CatalogExistsRule()
        result = rule.check(tmp_path)

        assert result.passed is False
        assert ".portolan" in result.message

    @pytest.mark.unit
    def test_has_error_severity(self) -> None:
        """Missing catalog is an ERROR (blocking)."""
        rule = CatalogExistsRule()
        assert rule.severity == Severity.ERROR

    @pytest.mark.unit
    def test_provides_fix_hint_on_failure(self, tmp_path: Path) -> None:
        """Failure includes hint to run 'portolan init'."""
        rule = CatalogExistsRule()
        result = rule.check(tmp_path)

        assert result.fix_hint is not None
        assert "init" in result.fix_hint.lower()

    @pytest.mark.unit
    def test_fails_when_portolan_is_file_not_dir(self, tmp_path: Path) -> None:
        """Rule fails when .portolan exists but is a file, not directory."""
        portolan_file = tmp_path / ".portolan"
        portolan_file.write_text("not a directory")

        rule = CatalogExistsRule()
        result = rule.check(tmp_path)

        assert result.passed is False
        assert "directory" in result.message.lower()
```

**Step 2: Run tests to verify they fail**

Run: `uv run pytest tests/unit/test_validation_rules.py::TestCatalogExistsRule -v`
Expected: FAIL with "ImportError: cannot import name 'CatalogExistsRule'"

**Step 3: Implement CatalogExistsRule**

Add to `portolan_cli/validation/rules.py`:

```python
class CatalogExistsRule(ValidationRule):
    """Check that .portolan directory exists.

    This is the most fundamental check - without the catalog directory,
    no other validation can proceed.
    """

    name = "catalog_exists"
    severity = Severity.ERROR
    description = "Verify .portolan directory exists"

    def check(self, catalog_path: Path) -> ValidationResult:
        """Check for .portolan directory."""
        portolan_dir = catalog_path / ".portolan"

        if not portolan_dir.exists():
            return self._fail(
                f"Catalog not found: {portolan_dir} does not exist",
                fix_hint="Run 'portolan init' to create a catalog",
            )

        if not portolan_dir.is_dir():
            return self._fail(
                f"Invalid catalog: {portolan_dir} exists but is not a directory",
                fix_hint="Remove the file and run 'portolan init'",
            )

        return self._pass(f"Catalog directory exists: {portolan_dir}")
```

**Step 4: Run tests to verify they pass**

Run: `uv run pytest tests/unit/test_validation_rules.py::TestCatalogExistsRule -v`
Expected: All 5 tests PASS

**Step 5: Commit**

```bash
git add portolan_cli/validation/rules.py tests/unit/test_validation_rules.py
git commit -m "$(cat <<'EOF'
feat(validation): add CatalogExistsRule

First concrete validation rule - checks that .portolan directory exists.
Includes fix hints pointing to 'portolan init'.

Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>
EOF
)"
```

---

## Task 4: CatalogJsonValidRule - JSON Structure Check

Check that catalog.json exists and is valid JSON.

**Files:**
- Modify: `portolan_cli/validation/rules.py`
- Test: `tests/unit/test_validation_rules.py` (extend)

**Step 1: Write failing tests for CatalogJsonValidRule**

Add to `tests/unit/test_validation_rules.py`:

```python
from portolan_cli.validation.rules import (
    ValidationRule,
    CatalogExistsRule,
    CatalogJsonValidRule,
)


class TestCatalogJsonValidRule:
    """Tests for CatalogJsonValidRule."""

    @pytest.fixture
    def catalog_dir(self, tmp_path: Path) -> Path:
        """Create a .portolan directory for testing."""
        portolan_dir = tmp_path / ".portolan"
        portolan_dir.mkdir()
        return portolan_dir

    @pytest.mark.unit
    def test_passes_when_catalog_json_valid(self, tmp_path: Path, catalog_dir: Path) -> None:
        """Rule passes when catalog.json exists and is valid JSON."""
        catalog_file = catalog_dir / "catalog.json"
        catalog_file.write_text('{"type": "Catalog"}')

        rule = CatalogJsonValidRule()
        result = rule.check(tmp_path)

        assert result.passed is True

    @pytest.mark.unit
    def test_fails_when_catalog_json_missing(self, tmp_path: Path, catalog_dir: Path) -> None:
        """Rule fails when catalog.json is missing."""
        rule = CatalogJsonValidRule()
        result = rule.check(tmp_path)

        assert result.passed is False
        assert "catalog.json" in result.message

    @pytest.mark.unit
    def test_fails_when_catalog_json_invalid(self, tmp_path: Path, catalog_dir: Path) -> None:
        """Rule fails when catalog.json is not valid JSON."""
        catalog_file = catalog_dir / "catalog.json"
        catalog_file.write_text("not valid json {{{")

        rule = CatalogJsonValidRule()
        result = rule.check(tmp_path)

        assert result.passed is False
        assert "invalid" in result.message.lower() or "parse" in result.message.lower()

    @pytest.mark.unit
    def test_fails_when_catalog_json_empty(self, tmp_path: Path, catalog_dir: Path) -> None:
        """Rule fails when catalog.json is empty."""
        catalog_file = catalog_dir / "catalog.json"
        catalog_file.write_text("")

        rule = CatalogJsonValidRule()
        result = rule.check(tmp_path)

        assert result.passed is False

    @pytest.mark.unit
    def test_has_error_severity(self) -> None:
        """Invalid catalog.json is an ERROR (blocking)."""
        rule = CatalogJsonValidRule()
        assert rule.severity == Severity.ERROR

    @pytest.mark.unit
    def test_provides_fix_hint_on_failure(self, tmp_path: Path, catalog_dir: Path) -> None:
        """Failure includes hint for remediation."""
        rule = CatalogJsonValidRule()
        result = rule.check(tmp_path)

        assert result.fix_hint is not None

    @pytest.mark.unit
    def test_fails_gracefully_when_portolan_dir_missing(self, tmp_path: Path) -> None:
        """Rule fails cleanly when .portolan doesn't exist."""
        rule = CatalogJsonValidRule()
        result = rule.check(tmp_path)

        assert result.passed is False
        # Should not raise an exception
```

**Step 2: Run tests to verify they fail**

Run: `uv run pytest tests/unit/test_validation_rules.py::TestCatalogJsonValidRule -v`
Expected: FAIL with "ImportError: cannot import name 'CatalogJsonValidRule'"

**Step 3: Implement CatalogJsonValidRule**

Add to `portolan_cli/validation/rules.py`:

```python
import json


class CatalogJsonValidRule(ValidationRule):
    """Check that catalog.json exists and is valid JSON.

    This rule does NOT check STAC schema compliance - only that the
    file exists and can be parsed as JSON.
    """

    name = "catalog_json_valid"
    severity = Severity.ERROR
    description = "Verify catalog.json exists and is valid JSON"

    def check(self, catalog_path: Path) -> ValidationResult:
        """Check for valid catalog.json."""
        catalog_file = catalog_path / ".portolan" / "catalog.json"

        if not catalog_file.exists():
            return self._fail(
                f"Missing catalog.json: {catalog_file} does not exist",
                fix_hint="Run 'portolan init' to create a catalog, or restore from backup",
            )

        try:
            content = catalog_file.read_text()
            if not content.strip():
                return self._fail(
                    f"Empty catalog.json: {catalog_file} has no content",
                    fix_hint="Run 'portolan check --fix' to regenerate catalog.json",
                )
            json.loads(content)
        except json.JSONDecodeError as e:
            return self._fail(
                f"Invalid JSON in catalog.json: {e}",
                fix_hint="Fix the JSON syntax error or restore from backup",
            )
        except OSError as e:
            return self._fail(
                f"Cannot read catalog.json: {e}",
                fix_hint="Check file permissions",
            )

        return self._pass(f"catalog.json is valid JSON: {catalog_file}")
```

**Step 4: Run tests to verify they pass**

Run: `uv run pytest tests/unit/test_validation_rules.py::TestCatalogJsonValidRule -v`
Expected: All 7 tests PASS

**Step 5: Commit**

```bash
git add portolan_cli/validation/rules.py tests/unit/test_validation_rules.py
git commit -m "$(cat <<'EOF'
feat(validation): add CatalogJsonValidRule

Checks that catalog.json exists and is valid JSON.
Does not validate STAC schema - that's a separate rule.

Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>
EOF
)"
```

---

## Task 5: StacFieldsRule - Required STAC Fields

Check that catalog.json has required STAC Catalog fields.

**Files:**
- Modify: `portolan_cli/validation/rules.py`
- Test: `tests/unit/test_validation_rules.py` (extend)

**Step 1: Write failing tests for StacFieldsRule**

Add to `tests/unit/test_validation_rules.py`:

```python
from portolan_cli.validation.rules import (
    ValidationRule,
    CatalogExistsRule,
    CatalogJsonValidRule,
    StacFieldsRule,
)
import json


class TestStacFieldsRule:
    """Tests for StacFieldsRule."""

    @pytest.fixture
    def catalog_dir(self, tmp_path: Path) -> Path:
        """Create a .portolan directory for testing."""
        portolan_dir = tmp_path / ".portolan"
        portolan_dir.mkdir()
        return portolan_dir

    def _write_catalog(self, catalog_dir: Path, data: dict) -> None:
        """Helper to write catalog.json."""
        catalog_file = catalog_dir / "catalog.json"
        catalog_file.write_text(json.dumps(data))

    @pytest.mark.unit
    def test_passes_with_all_required_fields(self, tmp_path: Path, catalog_dir: Path) -> None:
        """Rule passes when all required STAC fields are present."""
        self._write_catalog(catalog_dir, {
            "type": "Catalog",
            "stac_version": "1.0.0",
            "id": "my-catalog",
            "description": "Test catalog",
            "links": [],
        })

        rule = StacFieldsRule()
        result = rule.check(tmp_path)

        assert result.passed is True

    @pytest.mark.unit
    def test_fails_when_type_missing(self, tmp_path: Path, catalog_dir: Path) -> None:
        """Rule fails when 'type' field is missing."""
        self._write_catalog(catalog_dir, {
            "stac_version": "1.0.0",
            "id": "my-catalog",
            "description": "Test catalog",
            "links": [],
        })

        rule = StacFieldsRule()
        result = rule.check(tmp_path)

        assert result.passed is False
        assert "type" in result.message

    @pytest.mark.unit
    def test_fails_when_type_wrong(self, tmp_path: Path, catalog_dir: Path) -> None:
        """Rule fails when 'type' is not 'Catalog'."""
        self._write_catalog(catalog_dir, {
            "type": "Collection",  # Wrong type
            "stac_version": "1.0.0",
            "id": "my-catalog",
            "description": "Test catalog",
            "links": [],
        })

        rule = StacFieldsRule()
        result = rule.check(tmp_path)

        assert result.passed is False
        assert "Catalog" in result.message

    @pytest.mark.unit
    def test_fails_when_stac_version_missing(self, tmp_path: Path, catalog_dir: Path) -> None:
        """Rule fails when 'stac_version' field is missing."""
        self._write_catalog(catalog_dir, {
            "type": "Catalog",
            "id": "my-catalog",
            "description": "Test catalog",
            "links": [],
        })

        rule = StacFieldsRule()
        result = rule.check(tmp_path)

        assert result.passed is False
        assert "stac_version" in result.message

    @pytest.mark.unit
    def test_fails_when_id_missing(self, tmp_path: Path, catalog_dir: Path) -> None:
        """Rule fails when 'id' field is missing."""
        self._write_catalog(catalog_dir, {
            "type": "Catalog",
            "stac_version": "1.0.0",
            "description": "Test catalog",
            "links": [],
        })

        rule = StacFieldsRule()
        result = rule.check(tmp_path)

        assert result.passed is False
        assert "id" in result.message

    @pytest.mark.unit
    def test_fails_when_description_missing(self, tmp_path: Path, catalog_dir: Path) -> None:
        """Rule fails when 'description' field is missing."""
        self._write_catalog(catalog_dir, {
            "type": "Catalog",
            "stac_version": "1.0.0",
            "id": "my-catalog",
            "links": [],
        })

        rule = StacFieldsRule()
        result = rule.check(tmp_path)

        assert result.passed is False
        assert "description" in result.message

    @pytest.mark.unit
    def test_fails_when_links_missing(self, tmp_path: Path, catalog_dir: Path) -> None:
        """Rule fails when 'links' field is missing."""
        self._write_catalog(catalog_dir, {
            "type": "Catalog",
            "stac_version": "1.0.0",
            "id": "my-catalog",
            "description": "Test catalog",
        })

        rule = StacFieldsRule()
        result = rule.check(tmp_path)

        assert result.passed is False
        assert "links" in result.message

    @pytest.mark.unit
    def test_has_error_severity(self) -> None:
        """Missing required fields is an ERROR."""
        rule = StacFieldsRule()
        assert rule.severity == Severity.ERROR

    @pytest.mark.unit
    def test_provides_fix_hint(self, tmp_path: Path, catalog_dir: Path) -> None:
        """Failure includes hint for --fix."""
        self._write_catalog(catalog_dir, {"type": "Catalog"})

        rule = StacFieldsRule()
        result = rule.check(tmp_path)

        assert result.fix_hint is not None
        assert "--fix" in result.fix_hint

    @pytest.mark.unit
    def test_reports_all_missing_fields(self, tmp_path: Path, catalog_dir: Path) -> None:
        """Failure message lists all missing fields, not just first."""
        self._write_catalog(catalog_dir, {"type": "Catalog"})

        rule = StacFieldsRule()
        result = rule.check(tmp_path)

        # Should mention multiple missing fields
        assert "stac_version" in result.message
        assert "id" in result.message

    @pytest.mark.unit
    def test_fails_gracefully_when_catalog_json_missing(self, tmp_path: Path, catalog_dir: Path) -> None:
        """Rule fails cleanly when catalog.json doesn't exist."""
        rule = StacFieldsRule()
        result = rule.check(tmp_path)

        assert result.passed is False

    @pytest.mark.unit
    def test_fails_gracefully_when_catalog_json_invalid(self, tmp_path: Path, catalog_dir: Path) -> None:
        """Rule fails cleanly when catalog.json is not valid JSON."""
        catalog_file = catalog_dir / "catalog.json"
        catalog_file.write_text("not json")

        rule = StacFieldsRule()
        result = rule.check(tmp_path)

        assert result.passed is False
```

**Step 2: Run tests to verify they fail**

Run: `uv run pytest tests/unit/test_validation_rules.py::TestStacFieldsRule -v`
Expected: FAIL with "ImportError: cannot import name 'StacFieldsRule'"

**Step 3: Implement StacFieldsRule**

Add to `portolan_cli/validation/rules.py`:

```python
class StacFieldsRule(ValidationRule):
    """Check that catalog.json has required STAC Catalog fields.

    Required fields per STAC spec:
    - type: Must be "Catalog"
    - stac_version: STAC version string
    - id: Unique identifier
    - description: Human-readable description
    - links: Array of Link objects
    """

    name = "stac_fields"
    severity = Severity.ERROR
    description = "Verify catalog.json has required STAC Catalog fields"

    REQUIRED_FIELDS = ("type", "stac_version", "id", "description", "links")

    def check(self, catalog_path: Path) -> ValidationResult:
        """Check for required STAC fields."""
        catalog_file = catalog_path / ".portolan" / "catalog.json"

        # Try to load catalog.json
        try:
            content = catalog_file.read_text()
            catalog = json.loads(content)
        except (OSError, json.JSONDecodeError) as e:
            return self._fail(
                f"Cannot validate STAC fields: {e}",
                fix_hint="Fix catalog.json first (see catalog_json_valid rule)",
            )

        # Check type field specifically
        if "type" not in catalog:
            missing = [f for f in self.REQUIRED_FIELDS if f not in catalog]
            return self._fail(
                f"Missing required STAC fields: {', '.join(missing)}",
                fix_hint="Run 'portolan check --fix' to add default values",
            )

        if catalog.get("type") != "Catalog":
            return self._fail(
                f"Invalid type: expected 'Catalog', got '{catalog.get('type')}'",
                fix_hint="Change 'type' to 'Catalog' in catalog.json",
            )

        # Check other required fields
        missing = [f for f in self.REQUIRED_FIELDS if f not in catalog]
        if missing:
            return self._fail(
                f"Missing required STAC fields: {', '.join(missing)}",
                fix_hint="Run 'portolan check --fix' to add default values",
            )

        return self._pass("All required STAC fields present")
```

**Step 4: Run tests to verify they pass**

Run: `uv run pytest tests/unit/test_validation_rules.py::TestStacFieldsRule -v`
Expected: All 12 tests PASS

**Step 5: Commit**

```bash
git add portolan_cli/validation/rules.py tests/unit/test_validation_rules.py
git commit -m "$(cat <<'EOF'
feat(validation): add StacFieldsRule

Validates that catalog.json has all required STAC Catalog fields:
type, stac_version, id, description, links.

Reports all missing fields at once for better UX.

Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>
EOF
)"
```

---

## Task 6: Validation Runner (check function)

Create the `check()` function that runs all rules and returns a report.

**Files:**
- Modify: `portolan_cli/validation/__init__.py`
- Create: `portolan_cli/validation/runner.py`
- Test: `tests/unit/test_validation_runner.py`

**Step 1: Write failing tests for check()**

```python
# tests/unit/test_validation_runner.py
"""Tests for validation runner."""

from __future__ import annotations

import json
from pathlib import Path

import pytest

from portolan_cli.validation import check, ValidationReport
from portolan_cli.validation.results import Severity


class TestCheck:
    """Tests for check() function."""

    @pytest.fixture
    def valid_catalog(self, tmp_path: Path) -> Path:
        """Create a valid Portolan catalog."""
        portolan_dir = tmp_path / ".portolan"
        portolan_dir.mkdir()
        catalog_file = portolan_dir / "catalog.json"
        catalog_file.write_text(json.dumps({
            "type": "Catalog",
            "stac_version": "1.0.0",
            "id": "test-catalog",
            "description": "A test catalog",
            "links": [],
        }))
        return tmp_path

    @pytest.mark.unit
    def test_check_returns_validation_report(self, valid_catalog: Path) -> None:
        """check() returns a ValidationReport."""
        report = check(valid_catalog)
        assert isinstance(report, ValidationReport)

    @pytest.mark.unit
    def test_check_passes_for_valid_catalog(self, valid_catalog: Path) -> None:
        """check() passes for a valid catalog."""
        report = check(valid_catalog)
        assert report.passed is True

    @pytest.mark.unit
    def test_check_fails_when_no_portolan_dir(self, tmp_path: Path) -> None:
        """check() fails when .portolan doesn't exist."""
        report = check(tmp_path)
        assert report.passed is False
        assert len(report.errors) > 0

    @pytest.mark.unit
    def test_check_fails_when_catalog_json_missing(self, tmp_path: Path) -> None:
        """check() fails when catalog.json is missing."""
        portolan_dir = tmp_path / ".portolan"
        portolan_dir.mkdir()

        report = check(tmp_path)
        assert report.passed is False

    @pytest.mark.unit
    def test_check_fails_when_stac_fields_missing(self, tmp_path: Path) -> None:
        """check() fails when required STAC fields are missing."""
        portolan_dir = tmp_path / ".portolan"
        portolan_dir.mkdir()
        catalog_file = portolan_dir / "catalog.json"
        catalog_file.write_text('{"type": "Catalog"}')

        report = check(tmp_path)
        assert report.passed is False

    @pytest.mark.unit
    def test_check_runs_all_rules(self, valid_catalog: Path) -> None:
        """check() runs all registered rules."""
        report = check(valid_catalog)
        # Should have results from at least 3 rules
        assert len(report.results) >= 3

    @pytest.mark.unit
    def test_check_continues_after_early_failure(self, tmp_path: Path) -> None:
        """check() continues running rules even after early failures."""
        # No .portolan dir = first rule fails
        report = check(tmp_path)

        # Should still have run other rules (they'll fail gracefully)
        # At minimum, we get results from multiple rules
        assert len(report.results) >= 1  # At least catalog_exists
```

**Step 2: Run tests to verify they fail**

Run: `uv run pytest tests/unit/test_validation_runner.py -v`
Expected: FAIL with "ImportError: cannot import name 'check'"

**Step 3: Implement the runner**

```python
# portolan_cli/validation/runner.py
"""Validation runner that executes all rules against a catalog."""

from __future__ import annotations

from pathlib import Path

from portolan_cli.validation.results import ValidationReport, ValidationResult
from portolan_cli.validation.rules import (
    CatalogExistsRule,
    CatalogJsonValidRule,
    StacFieldsRule,
    ValidationRule,
)

# Default rules for v0.4 (catalog structure only)
DEFAULT_RULES: list[ValidationRule] = [
    CatalogExistsRule(),
    CatalogJsonValidRule(),
    StacFieldsRule(),
]


def check(
    catalog_path: Path,
    *,
    rules: list[ValidationRule] | None = None,
) -> ValidationReport:
    """Run validation rules against a catalog.

    Args:
        catalog_path: Path to the directory containing .portolan.
        rules: Optional list of rules to run. Defaults to DEFAULT_RULES.

    Returns:
        ValidationReport with results from all rules.
    """
    if rules is None:
        rules = DEFAULT_RULES

    results: list[ValidationResult] = []

    for rule in rules:
        result = rule.check(catalog_path)
        results.append(result)

    return ValidationReport(results=results)
```

**Step 4: Update validation/__init__.py**

```python
# portolan_cli/validation/__init__.py
"""Validation framework for Portolan catalogs.

This module provides the public API for validating catalogs:
- check(): Run validation rules against a catalog
- ValidationReport: Aggregate validation results
- ValidationRule: Base class for custom rules

Per ADR-0011, this is an MVP that validates catalog structure only.
Dataset-specific and remote validation comes in later versions.
"""

from portolan_cli.validation.results import (
    Severity,
    ValidationReport,
    ValidationResult,
)
from portolan_cli.validation.rules import ValidationRule
from portolan_cli.validation.runner import check

__all__ = [
    "Severity",
    "ValidationReport",
    "ValidationResult",
    "ValidationRule",
    "check",
]
```

**Step 5: Run tests to verify they pass**

Run: `uv run pytest tests/unit/test_validation_runner.py -v`
Expected: All 7 tests PASS

**Step 6: Commit**

```bash
git add portolan_cli/validation/runner.py portolan_cli/validation/__init__.py tests/unit/test_validation_runner.py
git commit -m "$(cat <<'EOF'
feat(validation): add check() function to run all validation rules

Provides the main validation entry point that:
- Runs all default rules (catalog_exists, catalog_json_valid, stac_fields)
- Continues after early failures for complete reporting
- Returns ValidationReport with all results

Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>
EOF
)"
```

---

## Task 7: CLI Command - portolan check

Add the `portolan check` CLI command.

**Files:**
- Modify: `portolan_cli/cli.py`
- Test: `tests/unit/test_cli_check.py`

**Step 1: Write failing tests for CLI**

```python
# tests/unit/test_cli_check.py
"""Tests for 'portolan check' CLI command."""

from __future__ import annotations

import json
from pathlib import Path

import pytest
from click.testing import CliRunner

from portolan_cli.cli import cli


class TestCheckCommand:
    """Tests for 'portolan check' CLI command."""

    @pytest.fixture
    def runner(self) -> CliRunner:
        """Create a CLI test runner."""
        return CliRunner()

    @pytest.fixture
    def valid_catalog(self, tmp_path: Path) -> Path:
        """Create a valid Portolan catalog."""
        portolan_dir = tmp_path / ".portolan"
        portolan_dir.mkdir()
        catalog_file = portolan_dir / "catalog.json"
        catalog_file.write_text(json.dumps({
            "type": "Catalog",
            "stac_version": "1.0.0",
            "id": "test-catalog",
            "description": "A test catalog",
            "links": [],
        }))
        return tmp_path

    @pytest.mark.unit
    def test_check_command_exists(self, runner: CliRunner) -> None:
        """'portolan check' command should exist."""
        result = runner.invoke(cli, ["check", "--help"])
        assert result.exit_code == 0
        assert "Validate" in result.output or "validate" in result.output

    @pytest.mark.unit
    def test_check_passes_for_valid_catalog(
        self, runner: CliRunner, valid_catalog: Path
    ) -> None:
        """'portolan check' returns exit code 0 for valid catalog."""
        result = runner.invoke(cli, ["check", str(valid_catalog)])
        assert result.exit_code == 0

    @pytest.mark.unit
    def test_check_fails_for_missing_catalog(
        self, runner: CliRunner, tmp_path: Path
    ) -> None:
        """'portolan check' returns exit code 1 for missing catalog."""
        result = runner.invoke(cli, ["check", str(tmp_path)])
        assert result.exit_code == 1

    @pytest.mark.unit
    def test_check_uses_current_dir_by_default(
        self, runner: CliRunner, valid_catalog: Path
    ) -> None:
        """'portolan check' without path uses current directory."""
        with runner.isolated_filesystem(temp_dir=valid_catalog):
            result = runner.invoke(cli, ["check"])
            assert result.exit_code == 0

    @pytest.mark.unit
    def test_check_shows_success_message(
        self, runner: CliRunner, valid_catalog: Path
    ) -> None:
        """'portolan check' shows success message when validation passes."""
        result = runner.invoke(cli, ["check", str(valid_catalog)])
        # Should contain checkmark or "pass" or "valid"
        assert "âœ“" in result.output or "pass" in result.output.lower() or "valid" in result.output.lower()

    @pytest.mark.unit
    def test_check_shows_error_details(
        self, runner: CliRunner, tmp_path: Path
    ) -> None:
        """'portolan check' shows error details when validation fails."""
        result = runner.invoke(cli, ["check", str(tmp_path)])
        # Should mention .portolan or catalog
        assert ".portolan" in result.output or "catalog" in result.output.lower()

    @pytest.mark.unit
    def test_check_json_output(
        self, runner: CliRunner, valid_catalog: Path
    ) -> None:
        """'portolan check --json' outputs JSON format."""
        result = runner.invoke(cli, ["check", str(valid_catalog), "--json"])
        assert result.exit_code == 0

        # Output should be valid JSON
        output = json.loads(result.output)
        assert "passed" in output
        assert output["passed"] is True

    @pytest.mark.unit
    def test_check_json_output_on_failure(
        self, runner: CliRunner, tmp_path: Path
    ) -> None:
        """'portolan check --json' outputs JSON even on failure."""
        result = runner.invoke(cli, ["check", str(tmp_path), "--json"])
        assert result.exit_code == 1

        output = json.loads(result.output)
        assert output["passed"] is False

    @pytest.mark.unit
    def test_check_verbose_shows_all_rules(
        self, runner: CliRunner, valid_catalog: Path
    ) -> None:
        """'portolan check --verbose' shows all rules, not just failures."""
        result = runner.invoke(cli, ["check", str(valid_catalog), "--verbose"])
        assert result.exit_code == 0

        # Should show rule names or descriptions
        assert "catalog_exists" in result.output.lower() or "exists" in result.output.lower()
```

**Step 2: Run tests to verify they fail**

Run: `uv run pytest tests/unit/test_cli_check.py -v`
Expected: FAIL with "Error: No such command 'check'"

**Step 3: Implement the CLI command**

Modify `portolan_cli/cli.py`:

```python
"""Portolan CLI - Command-line interface for managing cloud-native geospatial data.

The CLI is a thin wrapper around the Python API (see catalog.py).
All business logic lives in the library; the CLI handles user interaction.
"""

from __future__ import annotations

import json
from pathlib import Path

import click

from portolan_cli.catalog import Catalog, CatalogExistsError
from portolan_cli.output import detail, error, info, success, warn
from portolan_cli.validation import check as validate_catalog
from portolan_cli.validation.results import Severity


@click.group()
@click.version_option()
def cli() -> None:
    """Portolan - Publish and manage cloud-native geospatial data catalogs."""
    pass


@cli.command()
@click.argument("path", type=click.Path(path_type=Path), default=".")
def init(path: Path) -> None:
    """Initialize a new Portolan catalog.

    Creates a .portolan directory with a STAC catalog.json file.

    PATH is the directory where the catalog should be created (default: current directory).
    """
    try:
        Catalog.init(path)
        success(f"Initialized Portolan catalog in {path.resolve()}")
    except CatalogExistsError as err:
        error(f"Catalog already exists at {path.resolve()}")
        raise SystemExit(1) from err


@cli.command()
@click.argument("path", type=click.Path(path_type=Path, exists=True), default=".")
@click.option("--json", "json_output", is_flag=True, help="Output results as JSON")
@click.option("--verbose", "-v", is_flag=True, help="Show all validation rules, not just failures")
def check(path: Path, json_output: bool, verbose: bool) -> None:
    """Validate a Portolan catalog.

    Checks catalog structure and metadata against Portolan spec.

    PATH is the directory containing .portolan (default: current directory).
    """
    report = validate_catalog(path)

    if json_output:
        # JSON output mode
        click.echo(json.dumps(report.to_dict(), indent=2))
    else:
        # Human-readable output
        if verbose:
            # Show all rules
            for result in report.results:
                if result.passed:
                    success(result.message, verbose=verbose)
                elif result.severity == Severity.ERROR:
                    error(result.message)
                    if result.fix_hint:
                        detail(f"  Hint: {result.fix_hint}")
                else:
                    warn(result.message)
                    if result.fix_hint:
                        detail(f"  Hint: {result.fix_hint}")
        else:
            # Only show failures
            for result in report.results:
                if not result.passed:
                    if result.severity == Severity.ERROR:
                        error(result.message)
                    else:
                        warn(result.message)
                    if result.fix_hint:
                        detail(f"  Hint: {result.fix_hint}")

        # Summary
        if report.passed:
            success(f"Catalog valid ({len(report.results)} checks passed)")
        else:
            error_count = len(report.errors)
            warning_count = len(report.warnings)
            error(f"Validation failed: {error_count} error(s), {warning_count} warning(s)")

    # Exit code reflects validation result
    if not report.passed:
        raise SystemExit(1)
```

**Step 4: Run tests to verify they pass**

Run: `uv run pytest tests/unit/test_cli_check.py -v`
Expected: All 9 tests PASS

**Step 5: Commit**

```bash
git add portolan_cli/cli.py tests/unit/test_cli_check.py
git commit -m "$(cat <<'EOF'
feat(cli): add 'portolan check' command

Validates local catalogs against Portolan spec:
- Returns exit code 0 for valid catalogs, 1 for invalid
- --json flag for machine-readable output
- --verbose flag to show all rules, not just failures
- Includes fix hints for each failure

Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>
EOF
)"
```

---

## Task 8: Metadata Extraction - GeoParquet

Extract metadata (extent, schema, CRS) from GeoParquet files.

**Files:**
- Create: `portolan_cli/metadata/__init__.py`
- Create: `portolan_cli/metadata/geoparquet.py`
- Test: `tests/unit/test_metadata_geoparquet.py`

**Step 1: Write failing tests for GeoParquet metadata**

```python
# tests/unit/test_metadata_geoparquet.py
"""Tests for GeoParquet metadata extraction."""

from __future__ import annotations

from pathlib import Path

import pytest

from portolan_cli.metadata.geoparquet import extract_geoparquet_metadata, GeoParquetMetadata


class TestExtractGeoParquetMetadata:
    """Tests for extract_geoparquet_metadata()."""

    @pytest.mark.unit
    def test_returns_geoparquet_metadata(self, valid_points_parquet: Path) -> None:
        """Should return GeoParquetMetadata dataclass."""
        metadata = extract_geoparquet_metadata(valid_points_parquet)
        assert isinstance(metadata, GeoParquetMetadata)

    @pytest.mark.unit
    def test_extracts_bbox(self, valid_points_parquet: Path) -> None:
        """Should extract bounding box as (minx, miny, maxx, maxy)."""
        metadata = extract_geoparquet_metadata(valid_points_parquet)
        assert metadata.bbox is not None
        assert len(metadata.bbox) == 4
        minx, miny, maxx, maxy = metadata.bbox
        assert minx <= maxx
        assert miny <= maxy

    @pytest.mark.unit
    def test_extracts_crs(self, valid_points_parquet: Path) -> None:
        """Should extract CRS as EPSG code or WKT."""
        metadata = extract_geoparquet_metadata(valid_points_parquet)
        assert metadata.crs is not None
        # Should be EPSG:4326 or WGS 84 for our test fixture
        assert "4326" in str(metadata.crs) or "WGS" in str(metadata.crs)

    @pytest.mark.unit
    def test_extracts_geometry_type(self, valid_points_parquet: Path) -> None:
        """Should extract geometry type."""
        metadata = extract_geoparquet_metadata(valid_points_parquet)
        assert metadata.geometry_type is not None
        assert "Point" in metadata.geometry_type

    @pytest.mark.unit
    def test_extracts_feature_count(self, valid_points_parquet: Path) -> None:
        """Should extract feature count."""
        metadata = extract_geoparquet_metadata(valid_points_parquet)
        assert metadata.feature_count is not None
        assert metadata.feature_count > 0

    @pytest.mark.unit
    def test_extracts_schema(self, valid_points_parquet: Path) -> None:
        """Should extract column schema."""
        metadata = extract_geoparquet_metadata(valid_points_parquet)
        assert metadata.schema is not None
        assert isinstance(metadata.schema, dict)
        # Should have at least geometry column
        assert len(metadata.schema) > 0

    @pytest.mark.unit
    def test_extracts_geometry_column_name(self, valid_points_parquet: Path) -> None:
        """Should identify the geometry column name."""
        metadata = extract_geoparquet_metadata(valid_points_parquet)
        assert metadata.geometry_column is not None

    @pytest.mark.unit
    def test_raises_for_nonexistent_file(self, tmp_path: Path) -> None:
        """Should raise FileNotFoundError for missing file."""
        with pytest.raises(FileNotFoundError):
            extract_geoparquet_metadata(tmp_path / "missing.parquet")

    @pytest.mark.unit
    def test_raises_for_non_geoparquet(self, tmp_path: Path) -> None:
        """Should raise ValueError for non-GeoParquet file."""
        fake_file = tmp_path / "fake.parquet"
        fake_file.write_bytes(b"not a parquet file")

        with pytest.raises((ValueError, Exception)):  # pyarrow may raise different errors
            extract_geoparquet_metadata(fake_file)


class TestGeoParquetMetadata:
    """Tests for GeoParquetMetadata dataclass."""

    @pytest.mark.unit
    def test_to_stac_properties(self, valid_points_parquet: Path) -> None:
        """to_stac_properties() returns STAC-compatible dict."""
        metadata = extract_geoparquet_metadata(valid_points_parquet)
        props = metadata.to_stac_properties()

        assert isinstance(props, dict)
        # Should have standard STAC item properties structure

    @pytest.mark.unit
    def test_to_dict(self, valid_points_parquet: Path) -> None:
        """to_dict() returns complete metadata dict."""
        metadata = extract_geoparquet_metadata(valid_points_parquet)
        d = metadata.to_dict()

        assert "bbox" in d
        assert "crs" in d
        assert "geometry_type" in d
        assert "feature_count" in d
```

**Step 2: Run tests to verify they fail**

Run: `uv run pytest tests/unit/test_metadata_geoparquet.py -v`
Expected: FAIL with "ModuleNotFoundError: No module named 'portolan_cli.metadata'"

**Step 3: Implement GeoParquet metadata extraction**

```python
# portolan_cli/metadata/__init__.py
"""Metadata extraction for cloud-native geospatial formats.

This module provides functions to extract metadata from GeoParquet and COG files:
- extract_geoparquet_metadata(): Extract from GeoParquet
- extract_cog_metadata(): Extract from COG (future)

Metadata includes: bbox, CRS, schema, feature/pixel count.
"""

from portolan_cli.metadata.geoparquet import (
    GeoParquetMetadata,
    extract_geoparquet_metadata,
)

__all__ = [
    "GeoParquetMetadata",
    "extract_geoparquet_metadata",
]
```

```python
# portolan_cli/metadata/geoparquet.py
"""GeoParquet metadata extraction.

Uses pyarrow to read GeoParquet metadata without loading full data.
Extracts bbox, CRS, schema, and geometry type from file metadata.
"""

from __future__ import annotations

import json
from dataclasses import dataclass
from pathlib import Path
from typing import Any

import pyarrow.parquet as pq


@dataclass
class GeoParquetMetadata:
    """Metadata extracted from a GeoParquet file.

    Attributes:
        bbox: Bounding box as (minx, miny, maxx, maxy) or None.
        crs: CRS as EPSG code, WKT, or PROJJSON dict.
        geometry_type: Geometry type (Point, Polygon, etc.) or None.
        geometry_column: Name of the geometry column.
        feature_count: Number of features (rows).
        schema: Column names and types.
    """

    bbox: tuple[float, float, float, float] | None
    crs: str | dict[str, Any] | None
    geometry_type: str | None
    geometry_column: str | None
    feature_count: int
    schema: dict[str, str]

    def to_dict(self) -> dict[str, Any]:
        """Convert to JSON-serializable dict."""
        return {
            "bbox": list(self.bbox) if self.bbox else None,
            "crs": self.crs,
            "geometry_type": self.geometry_type,
            "geometry_column": self.geometry_column,
            "feature_count": self.feature_count,
            "schema": self.schema,
        }

    def to_stac_properties(self) -> dict[str, Any]:
        """Convert to STAC Item properties format."""
        props: dict[str, Any] = {}

        if self.geometry_type:
            props["geoparquet:geometry_type"] = self.geometry_type

        if self.feature_count:
            props["geoparquet:feature_count"] = self.feature_count

        return props


def extract_geoparquet_metadata(path: Path) -> GeoParquetMetadata:
    """Extract metadata from a GeoParquet file.

    Uses pyarrow to read file metadata without loading all data.
    Parses GeoParquet geo metadata from file's custom metadata.

    Args:
        path: Path to GeoParquet file.

    Returns:
        GeoParquetMetadata with extracted information.

    Raises:
        FileNotFoundError: If file doesn't exist.
        ValueError: If file is not valid GeoParquet.
    """
    if not path.exists():
        raise FileNotFoundError(f"File not found: {path}")

    # Open parquet file (metadata only)
    pf = pq.ParquetFile(path)
    metadata = pf.schema_arrow.metadata or {}

    # Parse GeoParquet geo metadata
    geo_metadata = _parse_geo_metadata(metadata)

    # Extract schema
    schema = {
        field.name: str(field.type) for field in pf.schema_arrow
    }

    # Get feature count from row groups
    feature_count = pf.metadata.num_rows

    # Extract geometry column info
    geometry_column = geo_metadata.get("primary_column", "geometry")
    column_meta = geo_metadata.get("columns", {}).get(geometry_column, {})

    # Extract bbox
    bbox = _extract_bbox(column_meta)

    # Extract CRS
    crs = _extract_crs(column_meta)

    # Extract geometry type
    geometry_type = _extract_geometry_type(column_meta)

    return GeoParquetMetadata(
        bbox=bbox,
        crs=crs,
        geometry_type=geometry_type,
        geometry_column=geometry_column,
        feature_count=feature_count,
        schema=schema,
    )


def _parse_geo_metadata(metadata: dict[bytes, bytes]) -> dict[str, Any]:
    """Parse GeoParquet geo metadata from Arrow schema metadata."""
    geo_key = b"geo"
    if geo_key not in metadata:
        # Not a GeoParquet file, return empty
        return {}

    try:
        return json.loads(metadata[geo_key].decode("utf-8"))
    except (json.JSONDecodeError, UnicodeDecodeError):
        return {}


def _extract_bbox(column_meta: dict[str, Any]) -> tuple[float, float, float, float] | None:
    """Extract bbox from column metadata."""
    bbox = column_meta.get("bbox")
    if bbox and len(bbox) >= 4:
        return (float(bbox[0]), float(bbox[1]), float(bbox[2]), float(bbox[3]))
    return None


def _extract_crs(column_meta: dict[str, Any]) -> str | dict[str, Any] | None:
    """Extract CRS from column metadata."""
    crs = column_meta.get("crs")
    if crs is None:
        return None

    # CRS can be PROJJSON dict or WKT string
    if isinstance(crs, dict):
        # Try to extract EPSG code from PROJJSON
        epsg = crs.get("id", {}).get("code")
        if epsg:
            return f"EPSG:{epsg}"
        return crs
    return str(crs)


def _extract_geometry_type(column_meta: dict[str, Any]) -> str | None:
    """Extract geometry type from column metadata."""
    geom_types = column_meta.get("geometry_types", [])
    if geom_types:
        # Return the first/primary type
        return geom_types[0] if isinstance(geom_types, list) else str(geom_types)

    # Fallback to geometry_type field
    return column_meta.get("geometry_type")
```

**Step 4: Run tests to verify they pass**

Run: `uv run pytest tests/unit/test_metadata_geoparquet.py -v`
Expected: All 11 tests PASS

**Step 5: Commit**

```bash
git add portolan_cli/metadata/__init__.py portolan_cli/metadata/geoparquet.py tests/unit/test_metadata_geoparquet.py
git commit -m "$(cat <<'EOF'
feat(metadata): add GeoParquet metadata extraction

Extracts metadata from GeoParquet files using pyarrow:
- bbox: Bounding box from geo metadata
- crs: CRS as EPSG code or PROJJSON
- geometry_type: Point, Polygon, etc.
- feature_count: Number of rows
- schema: Column names and types

Uses metadata-only reads for performance.

Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>
EOF
)"
```

---

## Task 9: Metadata Extraction - COG

Extract metadata (extent, CRS, bands) from Cloud-Optimized GeoTIFF files.

**Files:**
- Modify: `portolan_cli/metadata/__init__.py`
- Create: `portolan_cli/metadata/cog.py`
- Test: `tests/unit/test_metadata_cog.py`

**Step 1: Write failing tests for COG metadata**

```python
# tests/unit/test_metadata_cog.py
"""Tests for COG metadata extraction."""

from __future__ import annotations

from pathlib import Path

import pytest

from portolan_cli.metadata.cog import extract_cog_metadata, COGMetadata


class TestExtractCOGMetadata:
    """Tests for extract_cog_metadata()."""

    @pytest.mark.unit
    def test_returns_cog_metadata(self, valid_rgb_cog: Path) -> None:
        """Should return COGMetadata dataclass."""
        metadata = extract_cog_metadata(valid_rgb_cog)
        assert isinstance(metadata, COGMetadata)

    @pytest.mark.unit
    def test_extracts_bbox(self, valid_rgb_cog: Path) -> None:
        """Should extract bounding box as (minx, miny, maxx, maxy)."""
        metadata = extract_cog_metadata(valid_rgb_cog)
        assert metadata.bbox is not None
        assert len(metadata.bbox) == 4
        minx, miny, maxx, maxy = metadata.bbox
        assert minx <= maxx
        assert miny <= maxy

    @pytest.mark.unit
    def test_extracts_crs(self, valid_rgb_cog: Path) -> None:
        """Should extract CRS."""
        metadata = extract_cog_metadata(valid_rgb_cog)
        assert metadata.crs is not None

    @pytest.mark.unit
    def test_extracts_dimensions(self, valid_rgb_cog: Path) -> None:
        """Should extract width and height."""
        metadata = extract_cog_metadata(valid_rgb_cog)
        assert metadata.width is not None
        assert metadata.height is not None
        assert metadata.width > 0
        assert metadata.height > 0

    @pytest.mark.unit
    def test_extracts_band_count(self, valid_rgb_cog: Path) -> None:
        """Should extract number of bands."""
        metadata = extract_cog_metadata(valid_rgb_cog)
        assert metadata.band_count is not None
        assert metadata.band_count > 0

    @pytest.mark.unit
    def test_extracts_dtype(self, valid_rgb_cog: Path) -> None:
        """Should extract data type."""
        metadata = extract_cog_metadata(valid_rgb_cog)
        assert metadata.dtype is not None

    @pytest.mark.unit
    def test_extracts_nodata(self, valid_nodata_cog: Path) -> None:
        """Should extract nodata value if present."""
        metadata = extract_cog_metadata(valid_nodata_cog)
        # nodata may or may not be set, just verify it doesn't crash
        assert hasattr(metadata, "nodata")

    @pytest.mark.unit
    def test_extracts_resolution(self, valid_rgb_cog: Path) -> None:
        """Should extract pixel resolution."""
        metadata = extract_cog_metadata(valid_rgb_cog)
        assert metadata.resolution is not None

    @pytest.mark.unit
    def test_raises_for_nonexistent_file(self, tmp_path: Path) -> None:
        """Should raise FileNotFoundError for missing file."""
        with pytest.raises(FileNotFoundError):
            extract_cog_metadata(tmp_path / "missing.tif")

    @pytest.mark.unit
    def test_raises_for_non_raster(self, tmp_path: Path) -> None:
        """Should raise error for non-raster file."""
        fake_file = tmp_path / "fake.tif"
        fake_file.write_bytes(b"not a tiff file")

        with pytest.raises(Exception):  # rasterio raises various errors
            extract_cog_metadata(fake_file)


class TestCOGMetadata:
    """Tests for COGMetadata dataclass."""

    @pytest.mark.unit
    def test_to_dict(self, valid_rgb_cog: Path) -> None:
        """to_dict() returns complete metadata dict."""
        metadata = extract_cog_metadata(valid_rgb_cog)
        d = metadata.to_dict()

        assert "bbox" in d
        assert "crs" in d
        assert "width" in d
        assert "height" in d
        assert "band_count" in d

    @pytest.mark.unit
    def test_to_stac_properties(self, valid_rgb_cog: Path) -> None:
        """to_stac_properties() returns STAC-compatible dict."""
        metadata = extract_cog_metadata(valid_rgb_cog)
        props = metadata.to_stac_properties()

        assert isinstance(props, dict)
```

**Step 2: Run tests to verify they fail**

Run: `uv run pytest tests/unit/test_metadata_cog.py -v`
Expected: FAIL with "ImportError: cannot import name 'extract_cog_metadata'"

**Step 3: Implement COG metadata extraction**

```python
# portolan_cli/metadata/cog.py
"""COG (Cloud-Optimized GeoTIFF) metadata extraction.

Uses rasterio to read COG metadata without loading pixel data.
Extracts bbox, CRS, dimensions, bands, and resolution.
"""

from __future__ import annotations

from dataclasses import dataclass
from pathlib import Path
from typing import Any

import rasterio


@dataclass
class COGMetadata:
    """Metadata extracted from a COG file.

    Attributes:
        bbox: Bounding box as (minx, miny, maxx, maxy).
        crs: CRS as EPSG code or WKT.
        width: Image width in pixels.
        height: Image height in pixels.
        band_count: Number of bands.
        dtype: Data type (uint8, float32, etc.).
        nodata: Nodata value or None.
        resolution: Pixel resolution as (x_res, y_res).
    """

    bbox: tuple[float, float, float, float]
    crs: str | None
    width: int
    height: int
    band_count: int
    dtype: str
    nodata: float | None
    resolution: tuple[float, float]

    def to_dict(self) -> dict[str, Any]:
        """Convert to JSON-serializable dict."""
        return {
            "bbox": list(self.bbox),
            "crs": self.crs,
            "width": self.width,
            "height": self.height,
            "band_count": self.band_count,
            "dtype": self.dtype,
            "nodata": self.nodata,
            "resolution": list(self.resolution),
        }

    def to_stac_properties(self) -> dict[str, Any]:
        """Convert to STAC Item properties format."""
        props: dict[str, Any] = {
            "raster:bands": [
                {"data_type": self.dtype}
                for _ in range(self.band_count)
            ],
        }

        if self.nodata is not None:
            for band in props["raster:bands"]:
                band["nodata"] = self.nodata

        return props


def extract_cog_metadata(path: Path) -> COGMetadata:
    """Extract metadata from a COG file.

    Uses rasterio to read file metadata without loading pixel data.

    Args:
        path: Path to COG file.

    Returns:
        COGMetadata with extracted information.

    Raises:
        FileNotFoundError: If file doesn't exist.
        rasterio.errors.RasterioIOError: If file is not valid raster.
    """
    if not path.exists():
        raise FileNotFoundError(f"File not found: {path}")

    with rasterio.open(path) as src:
        # Extract CRS
        crs = None
        if src.crs:
            if src.crs.to_epsg():
                crs = f"EPSG:{src.crs.to_epsg()}"
            else:
                crs = src.crs.to_wkt()

        # Extract bbox from bounds
        bbox = (
            src.bounds.left,
            src.bounds.bottom,
            src.bounds.right,
            src.bounds.top,
        )

        # Extract resolution from transform
        resolution = (abs(src.transform.a), abs(src.transform.e))

        return COGMetadata(
            bbox=bbox,
            crs=crs,
            width=src.width,
            height=src.height,
            band_count=src.count,
            dtype=str(src.dtypes[0]),
            nodata=src.nodata,
            resolution=resolution,
        )
```

**Step 4: Update metadata/__init__.py**

```python
# portolan_cli/metadata/__init__.py
"""Metadata extraction for cloud-native geospatial formats.

This module provides functions to extract metadata from GeoParquet and COG files:
- extract_geoparquet_metadata(): Extract from GeoParquet
- extract_cog_metadata(): Extract from COG

Metadata includes: bbox, CRS, schema/bands, feature/pixel count.
"""

from portolan_cli.metadata.geoparquet import (
    GeoParquetMetadata,
    extract_geoparquet_metadata,
)
from portolan_cli.metadata.cog import (
    COGMetadata,
    extract_cog_metadata,
)

__all__ = [
    "COGMetadata",
    "GeoParquetMetadata",
    "extract_cog_metadata",
    "extract_geoparquet_metadata",
]
```

**Step 5: Run tests to verify they pass**

Run: `uv run pytest tests/unit/test_metadata_cog.py -v`
Expected: All 12 tests PASS

**Step 6: Commit**

```bash
git add portolan_cli/metadata/cog.py portolan_cli/metadata/__init__.py tests/unit/test_metadata_cog.py
git commit -m "$(cat <<'EOF'
feat(metadata): add COG metadata extraction

Extracts metadata from Cloud-Optimized GeoTIFFs using rasterio:
- bbox: Bounding box from image bounds
- crs: CRS as EPSG code or WKT
- width/height: Image dimensions
- band_count: Number of bands
- dtype: Data type (uint8, float32, etc.)
- nodata: Nodata value if set
- resolution: Pixel resolution

Uses metadata-only reads for performance.

Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>
EOF
)"
```

---

## Task 10: Run Full Test Suite and Lint

Verify all tests pass and code quality checks succeed.

**Files:**
- None (verification only)

**Step 1: Run all tests**

Run: `uv run pytest -v --tb=short`
Expected: All tests PASS

**Step 2: Run linting**

Run: `uv run ruff check .`
Expected: No errors

**Step 3: Run type checking**

Run: `uv run mypy portolan_cli`
Expected: No errors

**Step 4: Run pre-commit hooks**

Run: `uv run pre-commit run --all-files`
Expected: All hooks PASS

**Step 5: Commit any auto-fixes**

If ruff or pre-commit made auto-fixes:

```bash
git add -A
git commit -m "$(cat <<'EOF'
style: auto-fix linting issues

Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>
EOF
)"
```

---

## Task 11: Update ROADMAP.md

Mark v0.4 capabilities as implemented.

**Files:**
- Modify: `ROADMAP.md`

**Step 1: Update the roadmap**

Change v0.4 row to show completion:

```markdown
| **v0.4** | Metadata + validation | Extract metadata (extent, schema, CRS), define validation rules, `portolan check` for local catalogs âœ“ |
```

**Step 2: Commit**

```bash
git add ROADMAP.md
git commit -m "$(cat <<'EOF'
docs: mark v0.4 metadata + validation as complete

Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>
EOF
)"
```

---

## Summary

This plan implements v0.4 with:

1. **Validation Framework** (Tasks 1-6)
   - ValidationResult / ValidationReport data structures
   - ValidationRule abstract base class
   - Three concrete rules: CatalogExistsRule, CatalogJsonValidRule, StacFieldsRule
   - check() function to run all rules

2. **CLI Command** (Task 7)
   - `portolan check` with --json and --verbose flags
   - Proper exit codes (0=valid, 1=invalid)

3. **Metadata Extraction** (Tasks 8-9)
   - GeoParquetMetadata from pyarrow
   - COGMetadata from rasterio

4. **Quality Assurance** (Task 10)
   - Full test suite
   - Linting and type checking

Total: ~30 commits, ~60 tests, ~500 lines of code
