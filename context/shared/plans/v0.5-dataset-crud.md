# v0.5 Implementation Plan: Dataset CRUD

## Overview

Implement `dataset add`, `dataset list`, `dataset info`, and `dataset remove` commands. This is the core workflow for getting data into a Portolan catalog.

## Dependencies

**Already have (v0.3-v0.4):**
- Format detection (`portolan_cli/formats/detection.py`)
- Conversion wrappers (geoparquet-io, rio-cogeo)
- Metadata extraction (`portolan_cli/metadata/`)
- Validation framework (`portolan_cli/validation/`)
- `portolan init` (catalog structure)

**Need:**
- STAC generation (pystac is a dependency, not yet wired)
- `versions.json` read/write logic
- Dataset orchestration layer

## Workflow: `dataset add`

```
Input: file or directory path + options
                │
                ▼
┌───────────────────────────────────┐
│ 1. DETECT FORMAT                  │
│    • Is it raster, vector, or     │
│      unsupported?                 │
│    • Is it already cloud-native?  │
└───────────────────────────────────┘
                │
                ▼
┌───────────────────────────────────┐
│ 2. CONVERT (if needed)            │
│    • Vector → GeoParquet          │
│    • Raster → COG                 │
│    • Already cloud-native → skip  │
└───────────────────────────────────┘
                │
                ▼
┌───────────────────────────────────┐
│ 3. VALIDATE                       │
│    • Run validation rules         │
│    • Fail on errors, warn on      │
│      warnings                     │
└───────────────────────────────────┘
                │
                ▼
┌───────────────────────────────────┐
│ 4. EXTRACT METADATA               │
│    • Bounds, CRS, schema          │
│    • Row/pixel count              │
│    • File size, checksum          │
└───────────────────────────────────┘
                │
                ▼
┌───────────────────────────────────┐
│ 5. GENERATE STAC                  │
│    • Create/update collection.json│
│    • Create item.json             │
│    • Update catalog.json links    │
└───────────────────────────────────┘
                │
                ▼
┌───────────────────────────────────┐
│ 6. UPDATE VERSIONS.JSON           │
│    • Add version entry            │
│    • Record checksums             │
│    • Timestamp                    │
└───────────────────────────────────┘
                │
                ▼
┌───────────────────────────────────┐
│ 7. STAGE FILES                    │
│    • Copy data to .portolan/      │
│    • Write metadata files         │
└───────────────────────────────────┘
```

## CLI Interface

```bash
# Add single file to collection
portolan dataset add census.shp --collection demographics

# Add with metadata
portolan dataset add roads.geojson \
  --collection infrastructure \
  --title "Road Network" \
  --description "Primary and secondary roads"

# Add directory (all files become items in one collection)
portolan dataset add ./nairobi_data/ --collection nairobi

# Non-interactive mode (for automation)
portolan dataset add data.parquet --collection mydata --auto

# List datasets
portolan dataset list
portolan dataset list --collection demographics

# Get info
portolan dataset info demographics/census

# Remove
portolan dataset remove demographics/census
portolan dataset remove --collection demographics  # remove entire collection
```

## Implementation Steps

### Step 1: Versions module
Create `portolan_cli/versions.py`:
- `read_versions(path) -> VersionsFile`
- `write_versions(path, versions)`
- `add_version(versions, item_id, checksums, metadata)`
- Schema validation for versions.json

### Step 2: STAC generation module
Create `portolan_cli/stac.py`:
- `create_collection(name, metadata) -> pystac.Collection`
- `create_item(id, geometry, datetime, assets) -> pystac.Item`
- `update_catalog_links(catalog, collections)`
- Wrapper around pystac with our conventions

### Step 3: Dataset orchestration
Create `portolan_cli/dataset.py`:
- `add_dataset(path, collection, **options)` — the main workflow
- `list_datasets(collection=None) -> list[DatasetInfo]`
- `get_dataset_info(dataset_id) -> DatasetInfo`
- `remove_dataset(dataset_id)`

### Step 4: CLI commands
Update `portolan_cli/cli.py`:
- `@cli.group() def dataset()`
- `@dataset.command() def add()`
- `@dataset.command() def list()`
- `@dataset.command() def info()`
- `@dataset.command() def remove()`

### Step 5: Directory handling
In `add_dataset()`:
- If path is file: add as single item
- If path is directory: iterate files, add each as item to specified collection
- Recursive by default, `--no-recursive` to disable

## Test Plan

### Unit tests
- `test_versions.py` — versions.json read/write/update
- `test_stac.py` — STAC generation
- `test_dataset.py` — orchestration logic (mocked I/O)

### Integration tests
- Add shapefile → verify GeoParquet + STAC created
- Add GeoTIFF → verify COG + STAC created
- Add to existing collection → verify merge
- Add directory → verify all files processed
- Remove dataset → verify cleanup

### Fixtures needed
- Small shapefile (few features)
- Small GeoTIFF (few pixels)
- Pre-existing `.portolan/` catalog for merge tests

## Open Items

- [ ] Decide: thumbnail generation in v0.5 or defer?
- [ ] Decide: style.json generation in v0.5 or defer?
- [ ] Confirm pystac API for our STAC generation needs
